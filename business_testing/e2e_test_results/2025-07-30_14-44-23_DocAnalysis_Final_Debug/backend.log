2025-07-30 14:44:06,036 - asyncio - DEBUG - Using selector: KqueueSelector
INFO:     Started server process [78333]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
2025-07-30 14:44:16,900 - python_multipart.multipart - DEBUG - Calling on_part_begin with no data
2025-07-30 14:44:16,900 - python_multipart.multipart - DEBUG - Calling on_header_field with data[50:69]
2025-07-30 14:44:16,900 - python_multipart.multipart - DEBUG - Calling on_header_value with data[71:125]
2025-07-30 14:44:16,900 - python_multipart.multipart - DEBUG - Calling on_header_end with no data
2025-07-30 14:44:16,900 - python_multipart.multipart - DEBUG - Calling on_header_field with data[127:139]
2025-07-30 14:44:16,900 - python_multipart.multipart - DEBUG - Calling on_header_value with data[141:151]
2025-07-30 14:44:16,900 - python_multipart.multipart - DEBUG - Calling on_header_end with no data
2025-07-30 14:44:16,900 - python_multipart.multipart - DEBUG - Calling on_headers_finished with no data
2025-07-30 14:44:16,901 - python_multipart.multipart - DEBUG - Calling on_part_data with data[155:811]
2025-07-30 14:44:16,901 - python_multipart.multipart - DEBUG - Calling on_part_end with no data
2025-07-30 14:44:16,901 - python_multipart.multipart - DEBUG - Calling on_end with no data
2025-07-30 14:44:16,901 - __main__ - INFO - File upload request - session: e2e-test-doc-analysis-final-debug-1753901056, file: hermes_strategy.txt, correlation_id: 1ab8e42d-fa8c-4704-82a6-aa110a38002f
2025-07-30 14:44:16,901 - __main__ - INFO - File uploaded successfully - session: e2e-test-doc-analysis-final-debug-1753901056, file_id: 46556f2e-45fa-4cfc-ae83-e1ce515b96d9, correlation_id: 1ab8e42d-fa8c-4704-82a6-aa110a38002f
INFO:     127.0.0.1:51123 - "POST /upload?session_id=e2e-test-doc-analysis-final-debug-1753901056 HTTP/1.1" 200 OK
2025-07-30 14:44:17,333 - qna_pod - INFO - Using Anthropic LLM: claude-3-5-sonnet-20241022
2025-07-30 14:44:17,333 - qna_pod - INFO - LLM initialized: ChatAnthropic
2025-07-30 14:44:17,336 - qna_pod - INFO - Q&A Pod graph compiled successfully
2025-07-30 14:44:17,913 - document_analysis_pod - INFO - Using Anthropic LLM for Document Analysis: claude-3-5-sonnet-20241022
2025-07-30 14:44:17,922 - document_analysis_pod - INFO - Document Analysis Pod graph compiled successfully
2025-07-30 14:44:17,922 - __main__ - INFO - Chat request - session: e2e-test-doc-analysis-final-debug-1753901056, correlation_id: ce4ebbe4-ffac-49a9-a488-4be9b834a56b
2025-07-30 14:44:17,922 - document_analysis_pod - INFO - Starting document analysis for 1 files
2025-07-30 14:44:17,923 - document_analysis_pod - INFO - Loading documents for analysis
2025-07-30 14:44:17,923 - document_analysis_pod - INFO - ðŸ¤” Agent Reasoning - Loading Documents: Found 1 file(s) to analyze: hermes_strategy.txt. I will now load, parse, and split them into manageable chunks.
2025-07-30 14:44:17,924 - document_analysis_pod - ERROR - Error processing file hermes_strategy.txt: 'UploadedFileInfo' object has no attribute 'get'
2025-07-30 14:44:17,924 - document_analysis_pod - INFO - Planning document analysis approach
2025-07-30 14:44:17,924 - document_analysis_pod - INFO - ðŸ¤” Agent Reasoning - Planning Analysis: The user's request is: 'Summarize the key points and action items from the document.'. I have processed the document(s) into 0 chunk(s), totaling 0 characters.
2025-07-30 14:44:17,960 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'files': None, 'idempotency_key': 'stainless-python-retry-a24192e0-a173-4c31-90da-1b63b955680f', 'json_data': {'max_tokens': 1024, 'messages': [{'role': 'user', 'content': 'Analyze this user request for document analysis and break it down into components:\n\nUser Request: "Summarize the key points and action items from the document."\n\nTemplate Instructions (if provided): ""\n\nPlease identify:\n1. CORE_TASK: The main analysis task (e.g., summarize, extract key points, analyze data, etc.)\n2. INSTRUCTIONS: Specific requirements, format preferences, or focus areas\n\nRespond in this exact format:\nCORE_TASK: [main task]\nINSTRUCTIONS: [specific requirements]'}], 'model': 'claude-3-5-sonnet-20241022', 'temperature': 0.3}}
2025-07-30 14:44:17,961 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-07-30 14:44:17,965 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=None socket_options=None
2025-07-30 14:44:17,991 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12f1ff0e0>
2025-07-30 14:44:17,991 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x12f1ec440> server_hostname='api.anthropic.com' timeout=None
2025-07-30 14:44:18,012 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12f30ce10>
2025-07-30 14:44:18,013 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-30 14:44:18,013 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-07-30 14:44:18,013 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-30 14:44:18,013 - httpcore.http11 - DEBUG - send_request_body.complete
2025-07-30 14:44:18,013 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-30 14:44:20,150 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 30 Jul 2025 18:44:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-input-tokens-limit', b'160000'), (b'anthropic-ratelimit-input-tokens-remaining', b'160000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-07-30T18:44:18Z'), (b'anthropic-ratelimit-output-tokens-limit', b'32000'), (b'anthropic-ratelimit-output-tokens-remaining', b'32000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-07-30T18:44:20Z'), (b'anthropic-ratelimit-requests-limit', b'2000'), (b'anthropic-ratelimit-requests-remaining', b'1999'), (b'anthropic-ratelimit-requests-reset', b'2025-07-30T18:44:18Z'), (b'anthropic-ratelimit-tokens-limit', b'192000'), (b'anthropic-ratelimit-tokens-remaining', b'192000'), (b'anthropic-ratelimit-tokens-reset', b'2025-07-30T18:44:18Z'), (b'request-id', b'req_011CRdhQrJsRCkdGZDaDUwoa'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'anthropic-organization-id', b'31219faf-91cc-482b-93f4-cc5aadc25785'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'967701ad7a7fab21-YYZ'), (b'Content-Encoding', b'gzip')])
2025-07-30 14:44:20,152 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-07-30 14:44:20,152 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-30 14:44:20,153 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-07-30 14:44:20,153 - httpcore.http11 - DEBUG - response_closed.started
2025-07-30 14:44:20,153 - httpcore.http11 - DEBUG - response_closed.complete
2025-07-30 14:44:20,153 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Wed, 30 Jul 2025 18:44:20 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-input-tokens-limit': '160000', 'anthropic-ratelimit-input-tokens-remaining': '160000', 'anthropic-ratelimit-input-tokens-reset': '2025-07-30T18:44:18Z', 'anthropic-ratelimit-output-tokens-limit': '32000', 'anthropic-ratelimit-output-tokens-remaining': '32000', 'anthropic-ratelimit-output-tokens-reset': '2025-07-30T18:44:20Z', 'anthropic-ratelimit-requests-limit': '2000', 'anthropic-ratelimit-requests-remaining': '1999', 'anthropic-ratelimit-requests-reset': '2025-07-30T18:44:18Z', 'anthropic-ratelimit-tokens-limit': '192000', 'anthropic-ratelimit-tokens-remaining': '192000', 'anthropic-ratelimit-tokens-reset': '2025-07-30T18:44:18Z', 'request-id': 'req_011CRdhQrJsRCkdGZDaDUwoa', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'anthropic-organization-id': '31219faf-91cc-482b-93f4-cc5aadc25785', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '967701ad7a7fab21-YYZ', 'content-encoding': 'gzip'})
2025-07-30 14:44:20,153 - anthropic._base_client - DEBUG - request_id: req_011CRdhQrJsRCkdGZDaDUwoa
2025-07-30 14:44:20,169 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'files': None, 'idempotency_key': 'stainless-python-retry-3ea9d750-c57c-47d1-8d35-cc6df56567e2', 'json_data': {'max_tokens': 1024, 'messages': [{'role': 'user', 'content': 'You are an expert document analysis assistant. Your primary task is to create two prompts for a downstream AI model. These prompts will be used in a "refine" chain to analyze text provided by a user.\n\nThe user wants to accomplish this CORE TASK: "Summarize content"\nThey have provided these specific REQUIREMENTS: "Provide a comprehensive analysis"\n\nCRITICAL INSTRUCTION: The downstream model will be given text content from a document. Your generated prompts MUST explicitly reference this text content as the primary source for the analysis.\n\nCreate two prompts:\n1.  **INITIAL_PROMPT**: This prompt will be used on the very first chunk of text. It must instruct the AI to perform the user\'s request on the provided text.\n2.  **REFINE_PROMPT**: This prompt will be used on all subsequent chunks of text. It must instruct the AI to refine its previous analysis using the new text provided.\n\nIMPORTANT: Respond with ONLY the raw JSON object, without any markdown, comments, or other text.\nYour response must be in this exact format:\n{\n    "initial_prompt": "Your initial analysis prompt here. It MUST mention that the AI should use the following text content: {text}",\n    "refine_prompt": "Your refinement prompt here. It MUST mention that the AI should refine its existing answer: {existing_answer} using the following new text content: {text}"\n}'}], 'model': 'claude-3-5-sonnet-20241022', 'temperature': 0.3}}
2025-07-30 14:44:20,169 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-07-30 14:44:20,169 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-30 14:44:20,170 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-07-30 14:44:20,170 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-30 14:44:20,170 - httpcore.http11 - DEBUG - send_request_body.complete
2025-07-30 14:44:20,170 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-30 14:44:23,707 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 30 Jul 2025 18:44:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-input-tokens-limit', b'160000'), (b'anthropic-ratelimit-input-tokens-remaining', b'160000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-07-30T18:44:21Z'), (b'anthropic-ratelimit-output-tokens-limit', b'32000'), (b'anthropic-ratelimit-output-tokens-remaining', b'32000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-07-30T18:44:24Z'), (b'anthropic-ratelimit-requests-limit', b'2000'), (b'anthropic-ratelimit-requests-remaining', b'1999'), (b'anthropic-ratelimit-requests-reset', b'2025-07-30T18:44:20Z'), (b'anthropic-ratelimit-tokens-limit', b'192000'), (b'anthropic-ratelimit-tokens-remaining', b'192000'), (b'anthropic-ratelimit-tokens-reset', b'2025-07-30T18:44:21Z'), (b'request-id', b'req_011CRdhR1YzfAz1HHZ4eFKmL'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'anthropic-organization-id', b'31219faf-91cc-482b-93f4-cc5aadc25785'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'967701bafb7dab21-YYZ'), (b'Content-Encoding', b'gzip')])
2025-07-30 14:44:23,708 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-07-30 14:44:23,708 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-30 14:44:23,709 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-07-30 14:44:23,709 - httpcore.http11 - DEBUG - response_closed.started
2025-07-30 14:44:23,709 - httpcore.http11 - DEBUG - response_closed.complete
2025-07-30 14:44:23,710 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Wed, 30 Jul 2025 18:44:23 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-input-tokens-limit': '160000', 'anthropic-ratelimit-input-tokens-remaining': '160000', 'anthropic-ratelimit-input-tokens-reset': '2025-07-30T18:44:21Z', 'anthropic-ratelimit-output-tokens-limit': '32000', 'anthropic-ratelimit-output-tokens-remaining': '32000', 'anthropic-ratelimit-output-tokens-reset': '2025-07-30T18:44:24Z', 'anthropic-ratelimit-requests-limit': '2000', 'anthropic-ratelimit-requests-remaining': '1999', 'anthropic-ratelimit-requests-reset': '2025-07-30T18:44:20Z', 'anthropic-ratelimit-tokens-limit': '192000', 'anthropic-ratelimit-tokens-remaining': '192000', 'anthropic-ratelimit-tokens-reset': '2025-07-30T18:44:21Z', 'request-id': 'req_011CRdhR1YzfAz1HHZ4eFKmL', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'anthropic-organization-id': '31219faf-91cc-482b-93f4-cc5aadc25785', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '967701bafb7dab21-YYZ', 'content-encoding': 'gzip'})
2025-07-30 14:44:23,710 - anthropic._base_client - DEBUG - request_id: req_011CRdhR1YzfAz1HHZ4eFKmL
2025-07-30 14:44:23,711 - document_analysis_pod - INFO - Document analysis planning completed successfully
2025-07-30 14:44:23,713 - document_analysis_pod - INFO - Executing document analysis
2025-07-30 14:44:23,713 - document_analysis_pod - INFO - ðŸ¤” Agent Reasoning - Analyzing Documents: I will now analyse the 0 text chunk(s) comprehensively, iteratively updating the analysis to build a comprehensive answer.
2025-07-30 14:44:23,714 - document_analysis_pod - INFO - Synthesizing final results
2025-07-30 14:44:23,714 - document_analysis_pod - INFO - ðŸ¤” Agent Reasoning - Finalizing Results: The core analysis is complete. I will now format this into a clean, structured report for the user.
2025-07-30 14:44:23,715 - __main__ - INFO - Document Analysis result - files: 1, chunks: 0, status: synthesizing, correlation_id: ce4ebbe4-ffac-49a9-a488-4be9b834a56b
2025-07-30 14:44:23,715 - __main__ - INFO - Chat response generated - session: e2e-test-doc-analysis-final-debug-1753901056, correlation_id: ce4ebbe4-ffac-49a9-a488-4be9b834a56b
INFO:     127.0.0.1:51125 - "POST /chat HTTP/1.1" 200 OK
