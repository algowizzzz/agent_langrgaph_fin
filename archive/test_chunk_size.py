#!/usr/bin/env python3
"""
Test the 5k word chunk size implementation
"""

import asyncio
from tools.document_tools import split_document_into_chunks
from config import AI

def test_chunk_configuration():
    """Test the chunk size configuration"""
    
    print("ðŸ§ª Testing 5K Word Chunk Size Implementation")
    print("=" * 50)
    
    # Check config values
    ai_config = AI()
    chunk_size = getattr(ai_config, 'chunk_size', 'Not set')
    chunk_overlap = getattr(ai_config, 'chunk_overlap', 'Not set')
    
    print(f"ðŸ“Š Chunk size: {chunk_size}")
    print(f"ðŸ“Š Chunk overlap: {chunk_overlap}")
    
    # Test with sample large text
    large_text = "This is a test document. " * 2000  # ~10k words
    print(f"\nðŸ“„ Test text length: {len(large_text.split())} words")
    
    try:
        # Test chunking
        chunks = split_document_into_chunks(large_text, chunk_size=25000, chunk_overlap=1000)
        
        print(f"\nâœ… Chunking Results:")
        print(f"   Number of chunks: {len(chunks)}")
        
        for i, chunk in enumerate(chunks, 1):
            word_count = len(chunk.split())
            print(f"   Chunk {i}: {word_count} words")
            
        print(f"\nðŸŽ¯ Expected: 3-5 chunks for large documents (vs 26 previously)")
        print(f"ðŸŽ¯ Actual: {len(chunks)} chunks")
        
        if len(chunks) <= 5:
            print("âœ… Chunk reduction SUCCESS!")
        else:
            print("âŒ Chunk reduction not working as expected")
            
    except Exception as e:
        print(f"âŒ Error testing chunks: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_chunk_configuration()